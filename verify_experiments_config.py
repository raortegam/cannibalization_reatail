#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
verify_experiments_config.py

Script para verificar que todos los par√°metros de experiments.yaml
se aplicar√°n correctamente al ejecutar 01_run_sweep.py

Uso:
    python verify_experiments_config.py
"""

import yaml
from pathlib import Path
from pprint import pprint

def deep_update(d: dict, u: dict) -> dict:
    """Actualizaci√≥n recursiva de diccionarios (deep-merge) - igual que en 01_run_sweep.py"""
    import copy
    out = copy.deepcopy(d)
    for k, v in u.items():
        if isinstance(v, dict):
            out[k] = deep_update(out.get(k, {}), v)
        else:
            out[k] = v
    return out

def main():
    # Cargar archivos
    experiments_path = Path("experiments.yaml")
    base_config_path = Path("pipeline_config.yaml")
    
    if not experiments_path.exists():
        print(f"‚ùå No existe: {experiments_path}")
        return
    
    if not base_config_path.exists():
        print(f"‚ùå No existe: {base_config_path}")
        return
    
    with open(experiments_path, "r", encoding="utf-8") as f:
        suite = yaml.safe_load(f)
    
    with open(base_config_path, "r", encoding="utf-8") as f:
        base_cfg = yaml.safe_load(f)
    
    print("=" * 80)
    print("VERIFICACI√ìN DE CONFIGURACI√ìN DE EXPERIMENTOS")
    print("=" * 80)
    print()
    
    # Par√°metros cr√≠ticos que deben estar en todos los experimentos
    critical_params = [
        "meta_learners",
        "meta_hpo_trials",
        "meta_max_iter",
        "top_k_donors",
        "gsc_rank",
        "gsc_tau",
    ]
    
    experiments = suite["experiments"]
    
    for exp in experiments:
        exp_id = exp["id"]
        desc = exp.get("desc", "")
        overrides = exp.get("overrides", {})
        
        # Simular el merge que hace 01_run_sweep.py
        exp_cfg = deep_update(base_cfg, overrides)
        
        print(f"üìã Experimento: {exp_id}")
        print(f"   Descripci√≥n: {desc}")
        print(f"   Par√°metros cr√≠ticos:")
        
        params = exp_cfg.get("params", {})
        
        for param in critical_params:
            value = params.get(param, "‚ùå NO DEFINIDO")
            
            # Verificar si viene del override o del base
            is_override = param in overrides.get("params", {})
            source = "override" if is_override else "base_config"
            
            if value == "‚ùå NO DEFINIDO":
                print(f"      ‚ö†Ô∏è  {param}: {value}")
            else:
                print(f"      ‚úÖ {param}: {value} (desde {source})")
        
        # Verificar meta_learners espec√≠ficamente
        meta_learners = params.get("meta_learners", [])
        if isinstance(meta_learners, list):
            n_learners = len(meta_learners)
            if n_learners == 3:
                print(f"      ‚úÖ Correr√° {n_learners} meta-learners: {meta_learners}")
            elif n_learners > 0:
                print(f"      ‚ö†Ô∏è  Solo correr√° {n_learners} meta-learner(s): {meta_learners}")
            else:
                print(f"      ‚ùå NO correr√° meta-learners")
        
        print()
    
    print("=" * 80)
    print("RESUMEN")
    print("=" * 80)
    
    # Contar experimentos con configuraci√≥n completa
    complete = 0
    incomplete = []
    
    for exp in experiments:
        exp_id = exp["id"]
        overrides = exp.get("overrides", {})
        exp_cfg = deep_update(base_cfg, overrides)
        params = exp_cfg.get("params", {})
        
        has_all = all(params.get(p) is not None for p in critical_params)
        has_3_learners = len(params.get("meta_learners", [])) == 3
        
        if has_all and has_3_learners:
            complete += 1
        else:
            incomplete.append(exp_id)
    
    print(f"‚úÖ Experimentos con configuraci√≥n completa: {complete}/{len(experiments)}")
    
    if incomplete:
        print(f"‚ö†Ô∏è  Experimentos incompletos: {', '.join(incomplete)}")
    else:
        print("üéâ ¬°Todos los experimentos tienen configuraci√≥n completa!")
    
    print()
    print("=" * 80)
    print("VERIFICACI√ìN DE PAR√ÅMETROS ESPEC√çFICOS")
    print("=" * 80)
    print()
    
    # Verificar que todos tengan HPO mejorado
    print("üîç Verificando meta_hpo_trials:")
    for exp in experiments:
        exp_id = exp["id"]
        overrides = exp.get("overrides", {})
        exp_cfg = deep_update(base_cfg, overrides)
        params = exp_cfg.get("params", {})
        hpo_trials = params.get("meta_hpo_trials", "NO DEFINIDO")
        
        if hpo_trials == 100:
            print(f"   ‚úÖ {exp_id}: {hpo_trials} trials")
        elif hpo_trials == "NO DEFINIDO":
            print(f"   ‚ùå {exp_id}: NO DEFINIDO (usar√° default de ParamsConfig)")
        else:
            print(f"   ‚ö†Ô∏è  {exp_id}: {hpo_trials} trials (no es 100)")
    
    print()
    print("üîç Verificando meta_learners:")
    for exp in experiments:
        exp_id = exp["id"]
        overrides = exp.get("overrides", {})
        exp_cfg = deep_update(base_cfg, overrides)
        params = exp_cfg.get("params", {})
        learners = params.get("meta_learners", [])
        
        if len(learners) == 3 and set(learners) == {"x", "s", "t"}:
            print(f"   ‚úÖ {exp_id}: {learners}")
        elif len(learners) > 0:
            print(f"   ‚ö†Ô∏è  {exp_id}: {learners} (no son los 3)")
        else:
            print(f"   ‚ùå {exp_id}: [] (no correr√° meta-learners)")
    
    print()
    print("=" * 80)
    print("ESTIMACI√ìN DE EPISODIOS")
    print("=" * 80)
    print()
    
    total_episodes = 0
    for exp in experiments:
        exp_id = exp["id"]
        overrides = exp.get("overrides", {})
        exp_cfg = deep_update(base_cfg, overrides)
        params = exp_cfg.get("params", {})
        
        n_learners = len(params.get("meta_learners", []))
        # GSC + n_learners
        algorithms = 1 + n_learners
        
        # Estimaci√≥n conservadora: 100 episodios por algoritmo
        episodes_per_exp = algorithms * 100
        total_episodes += episodes_per_exp
        
        print(f"   {exp_id}: ~{episodes_per_exp} episodios (GSC + {n_learners} learners)")
    
    print()
    print(f"üìä Total estimado: ~{total_episodes} episodios en {len(experiments)} experimentos")
    print(f"üìä Promedio por experimento: ~{total_episodes // len(experiments)} episodios")
    print()
    print("=" * 80)

if __name__ == "__main__":
    main()
