# VariaciÃ³n de ParÃ¡metros por Experimento

## ğŸ¯ Resumen Ejecutivo

**El Step 3 (`select_pairs_and_donors.py`) NO varÃ­a entre experimentos** - todos los experimentos usan el mismo dataset base generado en el Step 3.

## ğŸ“Š QuÃ© VarÃ­a y QuÃ© NO VarÃ­a

### âŒ NO VarÃ­a Entre Experimentos

#### Step 3: `select_pairs_and_donors.py`

**Todos estos parÃ¡metros son FIJOS** (solo configurables por variables de entorno, no por `experiments.yaml`):

| ParÃ¡metro | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| `N_CANNIBALS_META` | **100** | NÃºmero de canÃ­bales para meta-learners |
| `N_VICTIMS_PER_I_META` | **50** | VÃ­ctimas por canÃ­bal para meta |
| `MAX_EPISODES_FOR_DONORS` | **150** | Episodios seleccionados para GSC |
| `EPISODE_SELECTION_STRATEGY` | `"top_delta_abs"` | Estrategia de selecciÃ³n |
| `P_PROMO_I_MIN` | 0.03 | MÃ­nimo % de promociÃ³n para canÃ­bales |
| `P_PROMO_I_MAX` | 0.25 | MÃ¡ximo % de promociÃ³n para canÃ­bales |
| `P_PROMO_J_MAX` | 0.10 | MÃ¡ximo % de promociÃ³n para vÃ­ctimas |
| `PRE_DAYS` | 90 | DÃ­as de perÃ­odo PRE |
| `POST_DAYS` | 30 | DÃ­as de perÃ­odo POST |
| `PRE_GAP` | 7 | Gap entre PRE y tratamiento |
| `WINDOW_START` | "2016-01-01" | Inicio de ventana temporal |
| `WINDOW_END` | "2017-06-30" | Fin de ventana temporal |

**Resultado:** Todos los experimentos parten del **mismo dataset base** de ~150 episodios.

### âœ… SÃ VarÃ­a Entre Experimentos

#### Step 4: `pre_algorithm.py` (Preprocesamiento)

| ParÃ¡metro | A_base | B_donors30 | C_donors5 | Otros |
|-----------|--------|------------|-----------|-------|
| `top_k_donors` | **20** | **30** | **5** | 10 |
| `lags_days` | [7,14,28,56] | [7,14,28,56] | [7,14,28,56] | **[7,14,28,56,84]** (D) |
| `fourier_k` | 3 | 3 | 3 | **6** (D,E) |
| `use_stl` | true | true | true | **false** (E) |
| `max_donor_promo_share` | 0.02 | 0.02 | **0.01** | 0.02 |
| `min_availability_share` | 0.90 | 0.90 | **0.95** | 0.90 |

#### Step 5: GSC (Synthetic Control)

| ParÃ¡metro | A_base | H_gsc_rank8 | Otros |
|-----------|--------|-------------|-------|
| `gsc_rank` | 5 | **8** | 5 |
| `gsc_tau` | 0.0001 | **0.00001** | 0.0001 |
| `gsc_alpha` | 0.0 | **0.001** | 0.0 |
| `gsc_cv_folds` | 3 | 3 | **5** (G) |
| `gsc_cv_holdout` | 21 | 21 | **35** (G) |

#### Step 6: Meta-learners

| ParÃ¡metro | Todos | F_treat_continuous |
|-----------|-------|-------------------|
| `meta_learners` | **["x","s","t"]** | ["x","s","t"] |
| `meta_hpo_trials` | **100** | 100 |
| `meta_max_iter` | **1000** | 1000 |
| `meta_cv_folds` | 3 | **5** (G) |
| `meta_cv_holdout` | 21 | **35** (G) |
| `treat_col_s` | "H_disc" | **"H_prop"** (F) |
| `treat_col_b` | "H_prop" | **"H_prop"** (F) |

## ğŸ”„ Flujo de Datos por Experimento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: select_pairs_and_donors.py                         â”‚
â”‚ âŒ NO VARÃA - Se ejecuta IGUAL para todos los experimentos â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dataset generado:                                           â”‚
â”‚ â€¢ ~5,000 episodios meta (100 canÃ­bales Ã— 50 vÃ­ctimas)      â”‚
â”‚ â€¢ 150 episodios GSC (top_delta_abs)                         â”‚
â”‚ â€¢ episodes_index.parquet (150 episodios)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: pre_algorithm.py                                    â”‚
â”‚ âœ… SÃ VARÃA - Diferentes configuraciones de preprocesamientoâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Experimento A_base:                                         â”‚
â”‚ â€¢ 20 donantes, lags [7,14,28,56], fourier=3, STL=on        â”‚
â”‚ â†’ Genera features especÃ­ficas para A_base                   â”‚
â”‚                                                             â”‚
â”‚ Experimento B_donors30:                                     â”‚
â”‚ â€¢ 30 donantes, lags [7,14,28,56], fourier=3, STL=on        â”‚
â”‚ â†’ Genera features diferentes (mÃ¡s donantes)                 â”‚
â”‚                                                             â”‚
â”‚ Experimento C_donors5_hiqual:                               â”‚
â”‚ â€¢ 5 donantes (alta calidad), lags [7,14,28,56]             â”‚
â”‚ â†’ Genera features con menos donantes pero mejor calidad     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Steps 5 & 6: Algoritmos (GSC + Meta)                       â”‚
â”‚ âœ… SÃ VARÃA - Diferentes hiperparÃ¡metros y configuraciones  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cada experimento usa:                                       â”‚
â”‚ â€¢ Mismo dataset base (150 episodios)                        â”‚
â”‚ â€¢ Features diferentes (por Step 4)                          â”‚
â”‚ â€¢ HiperparÃ¡metros diferentes (GSC rank, Meta HPO, etc.)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Implicaciones

### âœ… Ventajas de NO Variar Step 3

1. **ComparaciÃ³n Justa**
   - Todos los experimentos evalÃºan los mismos episodios
   - Las diferencias en resultados se deben SOLO a configuraciones de algoritmos
   - No hay sesgo por selecciÃ³n de episodios diferentes

2. **Eficiencia**
   - Step 3 es costoso (~30-45 min)
   - Se ejecuta una vez por experimento pero con mismos criterios
   - Ahorra tiempo total de ejecuciÃ³n

3. **Reproducibilidad**
   - Mismo dataset base garantiza reproducibilidad
   - FÃ¡cil de comparar mÃ©tricas entre experimentos

### âš ï¸ Limitaciones

1. **No se puede evaluar impacto de selecciÃ³n de episodios**
   - No puedes comparar "top_delta_abs" vs "random"
   - No puedes variar el nÃºmero de canÃ­bales/vÃ­ctimas por experimento

2. **Filtros de calidad fijos**
   - `P_PROMO_I_MIN/MAX`, `P_PROMO_J_MAX` son fijos
   - No puedes experimentar con diferentes criterios de selecciÃ³n

3. **Ventanas temporales fijas**
   - `PRE_DAYS`, `POST_DAYS`, `PRE_GAP` son fijos
   - No puedes experimentar con diferentes longitudes de ventana

## ğŸ”§ CÃ³mo Variar Step 3 (Si Necesitas)

Si quieres experimentar con diferentes configuraciones de Step 3, tienes que usar **variables de entorno**:

### OpciÃ³n 1: Por Experimento (Manual)

```bash
# Experimento con mÃ¡s canÃ­bales
set SPD_N_CANNIBALS_META=200
set SPD_MAX_EPISODES_FOR_DONORS=200
python 00_run_pipeline.py --config pipeline_config.yaml

# Experimento con selecciÃ³n aleatoria
set SPD_EPISODE_SELECTION=random
python 00_run_pipeline.py --config pipeline_config.yaml
```

### OpciÃ³n 2: Modificar CÃ³digo (Permanente)

Editar `src/preprocess_data/3. select_pairs_and_donors.py`:

```python
# LÃ­nea 226
N_CANNIBALS_META = _env_int("SPD_N_CANNIBALS_META", 200)  # Cambiar default

# LÃ­nea 240
MAX_EPISODES_FOR_DONORS = _env_int("SPD_MAX_EPISODES_FOR_DONORS", 200)

# LÃ­nea 241
EPISODE_SELECTION_STRATEGY = _env_str("SPD_EPISODE_SELECTION", "random")
```

### OpciÃ³n 3: Crear Variantes de Experimentos

PodrÃ­as crear scripts wrapper que configuren variables de entorno antes de ejecutar:

```bash
# run_experiment_A_large.bat
set SPD_N_CANNIBALS_META=200
set SPD_MAX_EPISODES_FOR_DONORS=200
python 00_run_pipeline.py --config pipeline_config.yaml
```

## ğŸ“Š Resumen de VariaciÃ³n por Paso

| Paso | Â¿VarÃ­a? | QuÃ© VarÃ­a | Impacto |
|------|---------|-----------|---------|
| **Step 1** | âŒ NO | Filtrado de datos | Mismo dataset limpio |
| **Step 2** | âŒ NO | CÃ¡lculo de H (exposure) | Mismo H para todos |
| **Step 3** | âŒ NO | SelecciÃ³n episodios | **Mismo dataset base (150 eps)** |
| **Step 4** | âœ… SÃ | Donantes, lags, fourier, STL | **Features diferentes** |
| **Step 5** | âœ… SÃ | GSC rank, tau, alpha, CV | **HiperparÃ¡metros GSC** |
| **Step 6** | âœ… SÃ | Meta HPO, CV, tratamiento | **HiperparÃ¡metros Meta** |
| **EDA** | âœ… SÃ | NÃºmero de grÃ¡ficos | VisualizaciÃ³n |

## ğŸ¯ ConclusiÃ³n

**La variaciÃ³n entre experimentos ocurre principalmente en:**

1. **Preprocesamiento (Step 4):**
   - NÃºmero de donantes (5, 10, 20, 30)
   - Features temporales (lags, fourier)
   - DescomposiciÃ³n (STL on/off)
   - Filtros de calidad

2. **Algoritmos (Steps 5 & 6):**
   - HiperparÃ¡metros GSC (rank, tau, alpha)
   - HiperparÃ¡metros Meta (HPO, max_iter)
   - Cross-validation (folds, holdout)
   - Tipo de tratamiento (discreto vs continuo)

**El dataset base (Step 3) es el MISMO para todos**, lo cual es **ideal para comparaciÃ³n cientÃ­fica**.

---

**RecomendaciÃ³n:** Si necesitas variar Step 3, considera crear un conjunto separado de experimentos con prefijo diferente (ej: "Z_large_dataset", "Z_random_selection") para no mezclar con los experimentos actuales.
